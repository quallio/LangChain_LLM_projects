{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VdkY3bxU2ecw",
        "outputId": "6c5a505e-0a9d-4b66-cc00-27bf1c2a66df"
      },
      "outputs": [],
      "source": [
        "!pip install langchain\n",
        "!pip install huggingface_hub\n",
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install unstructured\n",
        "!pip install pdf2image\n",
        "!pip install pdfminer\n",
        "!pip install pdfminer-six\n",
        "!pip install sentence_transformers\n",
        "!pip install chromadb\n",
        "!pip install arxiv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f27H_j4w239o",
        "outputId": "7531e7eb-d5ae-414d-f8d8-5e7092ca20d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
          ]
        }
      ],
      "source": [
        "from getpass import getpass\n",
        "\n",
        "HUGGINGFACEHUB_API_TOKEN = getpass()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "aAIqVTyd5Nuw"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = HUGGINGFACEHUB_API_TOKEN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "yrKLF3KO5QE2"
      },
      "outputs": [],
      "source": [
        "from langchain import HuggingFaceHub\n",
        "from langchain import PromptTemplate, LLMChain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "G9LWow6k5Xnv"
      },
      "outputs": [],
      "source": [
        "question = \"Who won the FIFA World Cup in the year 1994? \"\n",
        "template = \"\"\"Question: {question}\n",
        "\n",
        "Answer: Let's think step by step.\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(template=template, input_variables=[\"question\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "yjTOWwvt5Ybn"
      },
      "outputs": [],
      "source": [
        "# repo_id = \"OpenAssistant/stablelm-7b-sft-v7-epoch-3\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "PyrHy8whDJy_"
      },
      "outputs": [],
      "source": [
        "repo_id = \"tiiuae/falcon-7b-instruct\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "utwTFvqY5aTo"
      },
      "outputs": [],
      "source": [
        "llm = HuggingFaceHub(\n",
        "    repo_id=repo_id, task=\"text-generation\", model_kwargs={\"temperature\": 0.5, \"max_length\": 64}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "jGf7p-RQB9g5"
      },
      "outputs": [],
      "source": [
        "from langchain import PromptTemplate\n",
        "\n",
        "template = \"\"\"<|prompter|>{question}<|endoftext|><|assistant|>\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(template=template, input_variables=[\"question\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "RHCWCooYB-Zo"
      },
      "outputs": [],
      "source": [
        "from langchain import LLMChain\n",
        "\n",
        "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
        "\n",
        "question = \"What is the meaning of life?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "sGvkVA0cCTf3",
        "outputId": "0ff6cff0-47a6-4856-c979-bb9c1dc757de"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'The meaning of life is a philosophical question that has been debated by philosophers and scientists alike for centuries.'"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm_chain.run(question)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDDMGVYzD2PH"
      },
      "source": [
        "The model is working, now we will ask it to learn about a topic... the information it shoul learn we will be taken from a PDF file that is on line."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "4vNfISeUFaFt"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import OnlinePDFLoader\n",
        "\n",
        "loader = OnlinePDFLoader(\"https://arxiv.org/pdf/1911.01547.pdf\")\n",
        "document = loader.load()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NLy4jvKFn91"
      },
      "source": [
        "La forma en la que podemos usar un modelo de lenguaje para extraer informaci√≥n de un documento es pas√°ndole el contenido del documento como contexto, como parte del prompt. En el caso de un documento corto, como por ejemplo un post o un email, podemos pasar el documento entero como contexto. En el caso de un documento largo, como un libro o un pdf grande como el del ejemplo, es posible que no podamos pasar el documento entero ya que la cantidad de tokens que podemos pasar al modelo es limitada.\n",
        "\n",
        "Una de las grandes ventajas de GPT-4 es que es capaz de admitir contextos de hasta 64k tokens ü§Ø. Sin embargo, muchos de los modelos disponibles no superan los pocos miles de tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_oHK6WERFznt",
        "outputId": "22b7b4c1-ccf8-4194-c52c-5fcee4f3cca9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "178100"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(document[0].page_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUWqy0gAF6i9"
      },
      "source": [
        "Para poder llevar a cabo nuestro objetivo, tendremos que generar diferentes trozos de nuestro documento, diferentes chunks. De nuevo, LangChain nos ofrece funcionalidad para ello con sus text splitters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NounUttEF9C9",
        "outputId": "a579d48a-8121-4c6a-a7cd-151acbf429a5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:langchain.text_splitter:Created a chunk of size 1995, which is longer than the specified 1024\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1435, which is longer than the specified 1024\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1167, which is longer than the specified 1024\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1342, which is longer than the specified 1024\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1037, which is longer than the specified 1024\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1484, which is longer than the specified 1024\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1057, which is longer than the specified 1024\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1044, which is longer than the specified 1024\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1120, which is longer than the specified 1024\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1268, which is longer than the specified 1024\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1464, which is longer than the specified 1024\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1898, which is longer than the specified 1024\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1066, which is longer than the specified 1024\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1506, which is longer than the specified 1024\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1270, which is longer than the specified 1024\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1309, which is longer than the specified 1024\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1160, which is longer than the specified 1024\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1121, which is longer than the specified 1024\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1060, which is longer than the specified 1024\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1103, which is longer than the specified 1024\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1164, which is longer than the specified 1024\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1319, which is longer than the specified 1024\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1148, which is longer than the specified 1024\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1119, which is longer than the specified 1024\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1080, which is longer than the specified 1024\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "211"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1024, chunk_overlap=64)\n",
        "\n",
        "# texts = text_splitter.split_text(raw_text)\n",
        "documents = text_splitter.split_documents(document)\n",
        "\n",
        "len(documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdKrSEYLGZOM"
      },
      "source": [
        "En este ejemplo se han generado 211 documentos de una longitud aproximada de 1024 tokens con un solapamiento de 64 tokens entre ellos para evitar que se pierda informaci√≥n."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "kMLm1OZsGPo0",
        "outputId": "5511a54c-2913-4ae3-f3ee-c9bbdea5b592"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1Turing‚Äôs imitation game was largely meant as an argumentative device in a philosophical discussion, not as a literal test of intelligence. Mistaking it for a test representative of the goal of the Ô¨Åeld of AI has been an ongoing problem.\\n\\n3\\n\\nplicit deÔ¨Ånitions has been substituted with implicit deÔ¨Ånitions and biases that stretch back decades. Though invisible, these biases are still structuring many research efforts today, as illustrated by our Ô¨Åeld‚Äôs ongoing fascination with outperforming humans at board games or video games (a trend we discuss in I.3.5 and II.1). The goal of this document is to point out the implicit assumptions our Ô¨Åeld has been working from, correct some of its most salient biases, and provide an actionable formal deÔ¨Ånition and measurement benchmark for human-like general intelligence, leveraging modern insight from developmental cognitive psychology.\\n\\nI.2 DeÔ¨Åning intelligence: two divergent visions'"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "documents[10].page_content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "YRiE36ElGdTN",
        "outputId": "0ce4976e-b075-4b55-eabb-3b8658e99540"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'I.2 DeÔ¨Åning intelligence: two divergent visions\\n\\nLooked at in one way, everyone knows what intelligence is; looked at in another way, no one does.\\n\\nRobert J. Sternberg, 2000\\n\\nMany formal and informal deÔ¨Ånitions of intelligence have been proposed over the past few decades, although there is no existing scientiÔ¨Åc consensus around any single deÔ¨Ånition. Sternberg & Detterman noted in 1986 [87] that when two dozen prominent psychologists were asked to deÔ¨Åne intelligence, they all gave somewhat divergent answers. In the context of AI research, Legg and Hutter [53] summarized in 2007 no fewer than 70 deÔ¨Ånitions from the literature into a single statement: ‚ÄúIntelligence measures an agent‚Äôs ability to achieve goals in a wide range of environments.‚Äù'"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "documents[11].page_content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anYBth4HGlaU"
      },
      "source": [
        "¬øC√≥mo podemos ahora saber qu√© trozo de texto le tendremos que pasar al modelo en el prompt? Para ello primero generaremos embeddings de cada documento, una representaci√≥n num√©rica en forma de vector."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VuNo-2YGGnE8",
        "outputId": "538a47d0-0371-471d-fb18-cd13aabe07b8"
      },
      "outputs": [],
      "source": [
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "embeddings = HuggingFaceEmbeddings()\n",
        "\n",
        "query_result = embeddings.embed_query(documents[0].page_content)\n",
        "\n",
        "query_result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHzat2lsHVkN"
      },
      "source": [
        "Estos embedding ser√°n guardados e indexados en una base de datos vectorial, lo cual nos permitir√° una b√∫squeda y extracci√≥n eficiente de documentos pasando otro embedding como consulta. Como puedes imaginar, el objetivo ser√° el de recuperar aquellos documentos m√°s similares al prompt, los cuales (supuestamente), contendr√°n la informaci√≥n que buscamos. En este ejemplo usaremos Chroma como base de datos vectorial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "Iuq7HoBtLCIw"
      },
      "outputs": [],
      "source": [
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "vectorstore = Chroma.from_documents(documents, embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVesSa_oLQ5B"
      },
      "source": [
        "Ya tenemos todas las piezas que necesitamos para poder chatear con nuestro PDF. Simplemente nos queda generar la cadena adecuada para ello."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "gO0V0WnYLSpp"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import ConversationalRetrievalChain\n",
        "\n",
        "qa = ConversationalRetrievalChain.from_llm(llm, vectorstore.as_retriever(), return_source_documents=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "QAuk8EkJLbrB",
        "outputId": "898f1890-6235-487a-9000-28a2346991ff"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' Intelligence is the ability to achieve goals in a wide range of environments.\\n\\nIntroduction\\n\\n] I'"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chat_history = []\n",
        "query = \"What is the definition of intelligence?\"\n",
        "result = qa({\"question\": query, \"chat_history\": chat_history})\n",
        "result[\"answer\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZcqVjFHOwzV"
      },
      "source": [
        "En el siguiente recuadro vemos el trozo de texto que consider√≥ que es el m√°s cercano a lo que necesitamos y de all√≠ sac√≥ la respuesta a nuestra pregunta."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "7cG79YmfLg2w",
        "outputId": "f298451b-eb4d-45ea-b213-6ee5fd5f237c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'I.2 DeÔ¨Åning intelligence: two divergent visions\\n\\nLooked at in one way, everyone knows what intelligence is; looked at in another way, no one does.\\n\\nRobert J. Sternberg, 2000\\n\\nMany formal and informal deÔ¨Ånitions of intelligence have been proposed over the past few decades, although there is no existing scientiÔ¨Åc consensus around any single deÔ¨Ånition. Sternberg & Detterman noted in 1986 [87] that when two dozen prominent psychologists were asked to deÔ¨Åne intelligence, they all gave somewhat divergent answers. In the context of AI research, Legg and Hutter [53] summarized in 2007 no fewer than 70 deÔ¨Ånitions from the literature into a single statement: ‚ÄúIntelligence measures an agent‚Äôs ability to achieve goals in a wide range of environments.‚Äù'"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result['source_documents'][0].page_content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NB7e2QjTPtFU"
      },
      "source": [
        "A continuaci√≥n usaremos un AGENTE que nos facilita el trabajo. En este caso volvemos a utilizar el modelo LLM cargado anteriormente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "_f5UgtiwPySM"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import load_tools, initialize_agent, AgentType\n",
        "\n",
        "tools = load_tools(\n",
        "    [\"arxiv\"],\n",
        ")\n",
        "\n",
        "agent_chain = initialize_agent(\n",
        "    tools,\n",
        "    llm,\n",
        "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PuSEoo7GQFco"
      },
      "outputs": [],
      "source": [
        "agent_chain.run(\n",
        "    \"What's the paper On the measure of intelligence about?\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T8kWCfrAQiyf"
      },
      "outputs": [],
      "source": [
        "#  Solving output parser ERROR. The library has changed."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
